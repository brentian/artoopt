<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Chuwen Zhang" />
  <title>QAP</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="assets/pandoc.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
   var mathElements = document.getElementsByClassName("math");
   for (var i = 0; i < mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == "SPAN") {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains('display'),
      throwOnError: false,
      fleqn: false
     });
  }}});
  </script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@8.4.0/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({ startOnLoad: true });</script>
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">QAP</h1>
<p class="author">Chuwen Zhang</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#qap-the-problem">QAP, the problem</a>
<ul>
<li><a href="#differentiation">Differentiation</a></li>
</ul></li>
<li><a href="#mathscr-l_p-regularization"><span class="math inline">\mathscr L_p</span> regularization</a>
<ul>
<li><a href="#mathscr-l_2"><span class="math inline">\mathscr L_2</span></a>
<ul>
<li><a href="#naive">naive</a></li>
</ul></li>
<li><a href="#mathscr-l_1-exact-penalty"><span class="math inline">\mathscr L_1</span> exact penalty</a>
<ul>
<li><a href="#projected-gradient">Projected gradient</a></li>
<li><a href="#section"></a></li>
</ul></li>
</ul></li>
<li><a href="#reference">Reference</a></li>
</ul>
</nav>
<h1 id="qap-the-problem">QAP, the problem</h1>
<p>QAP, and alternative descriptions, see <span class="citation" data-cites="jiang_l_p-norm_2016"><a href="#ref-jiang_l_p-norm_2016" role="doc-biblioref">1</a></span></p>
<p><span class="math display">\begin{aligned}
&amp;\min_X f(X) = \textrm{tr}(A^\top XB X^\top)  \\
&amp; = \textrm{tr}(X^\top A^\top XB) &amp; x = \textrm{vec}(X)\\
&amp; = \left &lt;\textrm{vec}(X),  \textrm{vec}(A^\top X B )  \right &gt; \\
&amp; = \left &lt;\textrm{vec}(X), B^\top \otimes A^\top \cdot \textrm{vec}(X)  \right &gt; \\ 
&amp; = x^\top (B^\top \otimes A^\top) x\\ 
\mathbf{s.t.} &amp; \\ 
&amp;X \in \Pi_{n}
\end{aligned}</span></p>
<p>is the optimization problem on permutation matrices:</p>
<p><span class="math display"> \Pi_{n}=\left\{X \in \mathbb R ^{n \times n} \mid X e =X^{\top} e = e , X_{i j} \in\{0,1\}\right\}</span></p>
<p>The convex hull of permutation matrices, the Birkhoﬀ polytope, is defined:</p>
<p><span class="math display">D _{n}=\left\{X \in \mathbb R ^{n \times n} \mid X e =X^{\top} e = e , X \geq 0 \right\}</span></p>
<p>for the constraints, also equivalently: <span class="math display">\begin{aligned}
&amp; \textrm{tr}(XX^\top) = \left &lt;x, x \right &gt;_F= n, X \in D_{n}
\end{aligned}</span></p>
<h2 id="differentiation">Differentiation</h2>
<p><span class="math display">\begin{aligned}
&amp;  \nabla f = A^\top XB + AXB^\top \\
&amp; \nabla \textrm{tr}(XX^\top) = 2X
\end{aligned}</span></p>
<h1 id="mathscr-l_p-regularization"><span class="math inline">\mathscr L_p</span> regularization</h1>
<p>various form of regularized problem:</p>
<ul>
<li><p><span class="math inline">\mathscr L_0</span>: <span class="math inline">f(X) + \sigma ||X||_0</span> is exact to the original problem for efficiently large <span class="math inline">\sigma</span> <span class="citation" data-cites="jiang_l_p-norm_2016"><a href="#ref-jiang_l_p-norm_2016" role="doc-biblioref">1</a></span>, but the problem itself is still NP-hard.</p></li>
<li><p><span class="math inline">\mathscr L_p</span>: also suggested by <span class="citation" data-cites="jiang_l_p-norm_2016"><a href="#ref-jiang_l_p-norm_2016" role="doc-biblioref">1</a></span>, good in the sense:</p>
<ul>
<li>strongly concave and the global optimizer must be at vertices</li>
<li><strong>local optimizer is a permutation matrix</strong> if <span class="math inline">\sigma, \epsilon</span> satisfies some condition. Also, there is a lower bound for nonzero entries of the KKT points</li>
</ul></li>
</ul>
<p><span class="math display">\min _{X \in D _{n}} F_{\sigma, p, \epsilon}(X):=f(X)+\sigma\|X+\epsilon 1 \|_{p}^{p}</span></p>
<ul>
<li><span class="math inline">\mathscr L_2</span>, and is based on the fact that <span class="math inline">\Pi_n = D_n \bigcap \{X:\textrm{tr}(XX^\top) = n\}</span>, <span class="citation" data-cites="xia_efficient_2010"><a href="#ref-xia_efficient_2010" role="doc-biblioref">2</a></span></li>
</ul>
<p><span class="math display">\min_Xf(X)+\mu_{0} \cdot \textrm{tr} \left(X X^{\top}\right)</span></p>
<h2 id="mathscr-l_2"><span class="math inline">\mathscr L_2</span></h2>
<h3 id="naive">naive</h3>
<p><span class="math display">\begin{aligned}
&amp;\textrm{tr}(A^\top XB X^\top) + \mu_0 \cdot \textrm{tr}(X X^{\top}) \\
= &amp; x^\top (B^\top \otimes A^\top + \mu\cdot  \mathbf e_{n\times n}) x\\ 
\end{aligned} </span> this implies a LD-like method. (but not exactly)</p>
<h2 id="mathscr-l_1-exact-penalty"><span class="math inline">\mathscr L_1</span> exact penalty</h2>
<p>Motivated by the formulation using trace:</p>
<p><span class="math display">\begin{aligned}
&amp; \min_X  f \\
\mathbf{s.t.} &amp;\\
&amp;   \textrm{tr}(XX^\top ) -  n = 0 \\
&amp; X \in D_n
\end{aligned}</span></p>
<p>using <span class="math inline">\mathscr L_1</span> and by the factor that <span class="math inline">\forall X \in D_n ,\; \textrm{tr}(XX^\top)\le n</span>, we have:</p>
<p><span class="math display">\begin{aligned}
F_{\mu} &amp; =  f  + \mu\cdot | \textrm{tr}(XX^\top ) -  n| \\
 &amp;= f  + \mu\cdot n - \mu\cdot \textrm{tr}(XX^\top )
\end{aligned}</span></p>
<p>For sufficiently large penalty parameter <span class="math inline">\mu</span>, the problem solves the original problem.</p>
<p>The penalty method is very likely to become a concave function (even if the original one is convex), and thus it cannot be directly solved by conic solver.</p>
<h3 id="projected-gradient">Projected gradient</h3>
<p>Suppose we do projection on the penalized problem <span class="math inline">F_\mu</span> #### derivatives</p>
<p><span class="math display">\begin{aligned}
&amp; \nabla_X F_\mu  = A^\top XB + AXB^\top - 2\mu X \\
&amp; \nabla_\mu F_\mu  = n - \textrm{tr}(XX^\top) \\
&amp; \nabla_\Lambda F_\mu  = - X
\end{aligned}</span></p>
<h4 id="projected-derivative">projected derivative</h4>
<p><span class="math inline">PD</span>, a quadratic program</p>
<p><span class="math display">\begin{aligned}
&amp;\min_D ||\nabla F_\mu + D ||_F^2  \\
\mathbf{s.t.} &amp; \\
&amp;D e = D^\top e = 0 \\ 
&amp;D_{ij} = 0 \quad \textsf{if: } X_{ij} = 0\\
\end{aligned}</span></p>
<p>facts:</p>
<p>the space of <span class="math inline">D</span>, (<span class="math inline">e</span> is the vector of 1)</p>
<p><span class="math display">D \in \{D\in\mathbb{R}^{n\times n} : \; D e = D^\top e = 0;\; D_{ij} = 0,\;\forall  (i,j) \in M \}</span></p>
<p>how to formulate for <span class="math inline">F</span> such that <span class="math inline">\left &lt;F, D \right&gt;_F = 0</span> ?</p>
<p><span class="math inline">\mathbf I</span> is the identity matrix for active constraints of the <span class="math inline">X \ge 0</span> where <span class="math inline">\mathbf I_{ij} = 1</span> if <span class="math inline">X_{ij} = 0</span></p>
<ul>
<li><span class="math inline">\left &lt;D + \nabla F_\mu, D \right &gt; = 0</span></li>
</ul>
<p>dual problem for <span class="math inline">PD</span></p>
<ul>
<li><span class="math inline">\alpha,\beta,\Lambda</span> are Lagrange multipliers, <span class="math inline">\mathbf I</span> is the identity matrix for active constraints of the <span class="math inline">X \ge 0</span> where <span class="math inline">\mathbf I_{ij} = 1</span> if <span class="math inline">X_{ij} = 0</span></li>
</ul>
<p><span class="math display">\begin{aligned}
&amp; L_d = 1/2\cdot ||\nabla F_\mu + D ||_F^2 - \alpha^\top De - \beta^\top D^\top e -\Lambda \bullet D \bullet \mathbf I \\
\mathsf{KKT:} &amp;\\
&amp; \nabla F+D - ae^\top - e\beta^\top -\Lambda \bullet \mathbf{I} = 0\\
&amp; \nabla Fe - ae^\top e - e\beta^\top e -\Lambda \bullet \mathbf{I} e = 0\\
&amp; \nabla F^\top e  - \beta e^\top e - e\alpha^\top e - (\Lambda \bullet \mathbf{I})^\top e = 0
\end{aligned}</span></p>
<h3 id="section"></h3>
<h1 class="unnumbered" id="reference">Reference</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-jiang_l_p-norm_2016">
<p>[1] B. Jiang, Y.-F. Liu, and Z. Wen, “L_p-norm regularization algorithms for optimization over permutation matrices,” <em>SIAM Journal on Optimization</em>, vol. 26, no. 4, pp. 2284–2313, 2016.</p>
</div>
<div id="ref-xia_efficient_2010">
<p>[2] Y. Xia, “An efficient continuation method for quadratic assignment problems,” <em>Computers &amp; Operations Research</em>, vol. 37, no. 6, pp. 1027–1032, 2010.</p>
</div>
</div>
</body>
</html>
