<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Chuwen Zhang" />
  <title>Optimization as a Layer</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="assets/pandoc.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
   var mathElements = document.getElementsByClassName("math");
   var macros = [];
   for (var i = 0; i < mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == "SPAN") {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains('display'),
      throwOnError: false,
      macros: macros,
      fleqn: false
     });
  }}});
  </script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@8.4.0/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({ startOnLoad: true });</script>
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">Optimization as a Layer</h1>
<p class="author">Chuwen Zhang</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#optimization-as-a-layer">Optimization as a layer</a>
<ul>
<li><a href="#some-concepts">Some Concepts</a></li>
<li><a href="#differentiations">Differentiations</a></li>
<li><a href="#application">Application</a></li>
<li><a href="#reference">Reference</a></li>
</ul></li>
</ul>
</nav>
<h1 id="optimization-as-a-layer">Optimization as a layer</h1>
<h2 id="some-concepts">Some Concepts</h2>
<p>(.) is the alias:</p>
<ul>
<li>(<strong>e2e</strong>) End-to-end: raw-input to ultimate outputs of interests.
<ul>
<li>without tuned features/feature engineering</li>
</ul></li>
<li>(<strong>optlayer</strong>) Optimization as a Layer
<ul>
<li>inputs <span class="math inline">\to</span> outputs: <span class="math inline">x\to y</span>, includes an optimization problem <span class="math inline">y = \arg \min f(x)</span></li>
</ul></li>
<li>Differentiation, forward-and-backward pass.
<ul>
<li>for differentiable (convex) problem, Jacobian can be calculated via KKT.</li>
<li>for LP, can be calculated via interior point HSD formulation, <span class="citation" data-cites="ye_o_1994"><a href="#ref-ye_o_1994" role="doc-biblioref">Ye et al.</a> (<a href="#ref-ye_o_1994" role="doc-biblioref">1994</a>)</span></li>
<li>other specified solvers, for QP, conic, …</li>
</ul></li>
</ul>
<h2 id="differentiations">Differentiations</h2>
<p>[optimal condition] + solver</p>
<ul>
<li>KKT + QP solver, <span class="citation" data-cites="amos_optnet_2017"><a href="#ref-amos_optnet_2017" role="doc-biblioref">Amos and Kolter</a> (<a href="#ref-amos_optnet_2017" role="doc-biblioref">2017</a>)</span></li>
<li>CVX -&gt; Conic (HSD embedding) [optimal condition] -&gt; conic solver (SCS, …), <span class="citation" data-cites="amos_optnet_2017"><a href="#ref-amos_optnet_2017" role="doc-biblioref">Amos and Kolter</a> (<a href="#ref-amos_optnet_2017" role="doc-biblioref">2017</a>)</span></li>
<li>LP -&gt; HSD, <span class="citation" data-cites="mandi_interior_2020"><a href="#ref-mandi_interior_2020" role="doc-biblioref">Mandi and Guns</a> (<a href="#ref-mandi_interior_2020" role="doc-biblioref">2020</a>)</span></li>
</ul>
<h2 id="application">Application</h2>
<ul>
<li>e2e, stochastic programming (single stage.)
<ul>
<li>sp -&gt; deterministic.</li>
</ul></li>
<li>sensitivity analysis</li>
<li></li>
</ul>
<h2 id="reference">Reference</h2>
<!-- Q
  - not solve to optimal?
  - 
 -->
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-amos_optnet_2017" class="csl-entry" role="doc-biblioentry">
Amos B, Kolter JZ (2017) Optnet: <span>Differentiable</span> optimization as a layer in neural networks. <em>International <span>Conference</span> on <span>Machine</span> <span>Learning</span></em>. (PMLR), 136–145.
</div>
<div id="ref-mandi_interior_2020" class="csl-entry" role="doc-biblioentry">
Mandi J, Guns T (2020) Interior <span>Point</span> <span>Solving</span> for <span>LP</span>-based prediction+ optimisation. <em>arXiv preprint arXiv:2010.13943</em>.
</div>
<div id="ref-ye_o_1994" class="csl-entry" role="doc-biblioentry">
Ye Y, Todd MJ, Mizuno S (1994) An <span>O</span> (√ <span class="nocase">nL</span>)-iteration homogeneous and self-dual linear programming algorithm. <em>Mathematics of operations research</em> 19(1):53–67.
</div>
</div>
</body>
</html>
